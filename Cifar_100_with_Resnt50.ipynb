{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitin-vig/ERAv4S8/blob/main/Cifar_100_with_Resnt50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "cOSlh9n4c-hH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-GYmfW8dGpQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8UX7LDdHa0"
      },
      "source": [
        "\n",
        "\n",
        "# Cifar 100 with Resnt50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XzvJLus2WJ2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "UxaYbdi2dLBO"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from matplotlib import pyplot as plt\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4fYw485T0IV"
      },
      "source": [
        "**Compute Mean and Standard Deviation for Normalization of data**. Commented as it is needed only once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "-A43tRpdTzmU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "Uei6QCR0TD6V"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from torchvision import datasets, transforms\n",
        "# from torch.utils.data import DataLoader\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# def get_mean_and_std(dataloader):\n",
        "#     \"\"\"\n",
        "#     Calculate the mean and standard deviation of a dataset.\n",
        "\n",
        "#     Args:\n",
        "#         dataloader (DataLoader): The DataLoader for the dataset.\n",
        "\n",
        "#     Returns:\n",
        "#         tuple: The mean and standard deviation tensors for each channel.\n",
        "#     \"\"\"\n",
        "#     channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "#     for data, _ in tqdm(dataloader, desc=\"Calculating mean and std\"):\n",
        "#         # Mean over batch, height, and width, but not over the channels\n",
        "#         channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
        "#         channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
        "#         num_batches += 1\n",
        "\n",
        "#     mean = channels_sum / num_batches\n",
        "#     # Std = sqrt(E[X^2] - (E[X])^2)\n",
        "#     std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
        "#     return mean, std\n",
        "\n",
        "# # 1. Load the dataset without normalization (only convert to tensor)\n",
        "# # This will automatically download the dataset if it's not present\n",
        "# transform = transforms.Compose([transforms.ToTensor()])\n",
        "# train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# # 2. Create a DataLoader\n",
        "# train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# # 3. Get the mean and standard deviation\n",
        "# mean, std = get_mean_and_std(train_loader)\n",
        "\n",
        "# print('Calculated Mean:', mean)\n",
        "# print('Calculated Standard Deviation:', std)\n",
        "\n",
        "# 100%|██████████| 169M/169M [00:06<00:00, 27.9MB/s]\n",
        "# Calculating mean and std: 100%|██████████| 391/391 [00:07<00:00, 50.50it/s]\n",
        "# Calculated Mean: tensor([0.5070, 0.4865, 0.4409])\n",
        "# Calculated Standard Deviation: tensor([0.2673, 0.2564, 0.2761])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "RLvCZKLp7lh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca99aa3d-0396-4fb0-bfb0-1f3fa270a17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3906979243.py:48: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
            "  A.PadIfNeeded(min_height=40, min_width=40, border_mode=0, value=0, p=1.0),  # Pad first\n",
            "/tmp/ipython-input-3906979243.py:53: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(\n",
            "/tmp/ipython-input-3906979243.py:62: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n"
          ]
        }
      ],
      "source": [
        "# Train Phase transformations\n",
        "# train_transforms = transforms.Compose([\n",
        "\n",
        "#                                        transforms.ToTensor(),\n",
        "#                                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616),), # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values.\n",
        "#                                        A.CoarseDropout(num_holes_range=(1,1),hole_height_range=(16,16),hole_width_range=(16,16),p=0.5),\n",
        "#                                        A.HorizontalFlip(0.5),\n",
        "#                                        A.ShiftScaleRotate(shift_limit=1,scale_limit=1,rotate_limit=1,p=0.5)\n",
        "#                                        ])\n",
        "# Define your Albumentations pipeline\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "\n",
        "CIFAR_MEAN = (0.5070, 0.4865, 0.4409)\n",
        "CIFAR_STD  = (0.2673, 0.2564, 0.2761)\n",
        "\n",
        "# train_alb = A.Compose([\n",
        "#     # pad 4 px each side -> random crop 32x32 (equivalent to RandomCrop(pad=4))\n",
        "#     A.PadIfNeeded(min_height=36, min_width=36, border_mode=0, value=None),\n",
        "#     A.RandomCrop(height=32, width=32),\n",
        "\n",
        "#     # spatial\n",
        "#     A.HorizontalFlip(p=0.5),\n",
        "#     A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.08, rotate_limit=10, border_mode=0, p=0.5),\n",
        "\n",
        "#     # color / brightness / contrast variations\n",
        "#     A.OneOf([\n",
        "#         A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
        "#         A.HueSaturationValue(hue_shift_limit=8, sat_shift_limit=10, val_shift_limit=8),\n",
        "#         A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
        "#     ], p=0.8),\n",
        "\n",
        "#     # small blur / noise sometimes\n",
        "#     A.OneOf([A.GaussianBlur(blur_limit=(1,3)), A.GaussNoise(var_limit=(1.0, 10.0))], p=0.25),\n",
        "\n",
        "#     # CoarseDropout as Cutout: smaller holes for CIFAR (use max 6-8 px)\n",
        "#     A.CoarseDropout(max_holes=1, max_height=8, max_width=8,\n",
        "#                     min_holes=1, min_height=8, min_width=8,\n",
        "#                     fill_value=tuple([int(m * 255) for m in CIFAR_MEAN]),\n",
        "#                     p=0.5),\n",
        "\n",
        "#     A.Normalize(mean=CIFAR_MEAN, std=CIFAR_STD),\n",
        "#     ToTensorV2(),\n",
        "# ])\n",
        "\n",
        "train_alb = A.Compose([\n",
        "    A.PadIfNeeded(min_height=40, min_width=40, border_mode=0, value=0, p=1.0),  # Pad first\n",
        "    A.RandomCrop(32, 32, p=1.0),  # Then crop\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=15, p=0.5),\n",
        "    A.OneOf([\n",
        "        A.CoarseDropout(\n",
        "            max_holes=1,\n",
        "            max_height=16,\n",
        "            max_width=16,\n",
        "            min_height=8,\n",
        "            min_width=8,\n",
        "            fill_value=tuple([int(x * 255) for x in [0.5071, 0.4867, 0.4408]]),\n",
        "            p=1.0\n",
        "        ),\n",
        "        A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
        "    ], p=0.3),\n",
        "    A.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# test: only normalize + tensor\n",
        "test_alb = A.Compose([\n",
        "    A.Normalize(mean=CIFAR_MEAN, std=CIFAR_STD),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# wrapper functions for torchvision CIFAR100 dataset\n",
        "def alb_train_transform(img):\n",
        "    if not isinstance(img, np.ndarray):\n",
        "        img = np.array(img)\n",
        "    return train_alb(image=img)[\"image\"]\n",
        "\n",
        "def alb_test_transform(img):\n",
        "    if not isinstance(img, np.ndarray):\n",
        "        img = np.array(img)\n",
        "    return test_alb(image=img)[\"image\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "TRawLqCH7p0I"
      },
      "outputs": [],
      "source": [
        "train = datasets.CIFAR100('./data', train=True, download=True, transform=alb_train_transform)\n",
        "test = datasets.CIFAR100('./data', train=False, download=True, transform=alb_test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "iK8DvS4FSnSa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8PoAAuI7vNO",
        "outputId": "49d0667e-b166-48a5-f461-6a2510238a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? True\n"
          ]
        }
      ],
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "N8m3tkcbwa_c",
        "outputId": "cfd23f90-8139-4aaf-c4a1-7d162aa0cb4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..2.0253532].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..1.9259292].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..1.6080557].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..2.0253532].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..1.9117258].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..1.2978864].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..1.7106762].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..1.588373].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..1.8833189].\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 259, in _feed\n",
            "    reader_close()\n",
            "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 178, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 377, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..1.8265052].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..1.8833189].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8974658..1.1535935].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_data, batch_label = next(iter(train_loader))\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(12):\n",
        "  plt.subplot(3,4,i+1)\n",
        "  plt.tight_layout()\n",
        "  # plt.imshow(batch_data[i].squeeze(0), cmap='gray')\n",
        "  plt.imshow(batch_data[i].permute(1,2,0))\n",
        "\n",
        "  plt.title(batch_label[i].item())\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "gr757vIC7-Rt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Bottleneck block (same as before)\n",
        "class Bottleneck(nn.Module):\n",
        " expansion = 4\n",
        "\n",
        " def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "  super(Bottleneck, self).__init__()\n",
        "  self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "  self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "  self.conv2 = nn.Conv2d(\n",
        "   out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "  )\n",
        "  self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "  self.conv3 = nn.Conv2d(\n",
        "   out_channels, out_channels * self.expansion, kernel_size=1, bias=False\n",
        "  )\n",
        "  self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "  self.relu = nn.ReLU(inplace=True)\n",
        "  self.downsample = downsample\n",
        "\n",
        " def forward(self, x):\n",
        "  identity = x\n",
        "\n",
        "  out = self.conv1(x)\n",
        "  out = self.bn1(out)\n",
        "  out = self.relu(out)\n",
        "\n",
        "  out = self.conv2(out)\n",
        "  out = self.bn2(out)\n",
        "  out = self.relu(out)\n",
        "\n",
        "  out = self.conv3(out)\n",
        "  out = self.bn3(out)\n",
        "\n",
        "  if self.downsample is not None:\n",
        "   identity = self.downsample(x)\n",
        "\n",
        "  out += identity\n",
        "  out = self.relu(out)\n",
        "  return out\n",
        "\n",
        "\n",
        "# ResNet tailored for CIFAR (no initial 7x7 stride-2 conv + no maxpool)\n",
        "class ResNetCIFAR(nn.Module):\n",
        " def __init__(self, block, layers, num_classes=100):\n",
        "  super(ResNetCIFAR, self).__init__()\n",
        "  self.in_channels = 64\n",
        "\n",
        "  # Adjusted first conv for CIFAR (3x3, stride=1)\n",
        "  self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "  self.bn1 = nn.BatchNorm2d(64)\n",
        "  self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "  # NOTE: we do NOT use the 7x7 stride-2 conv or the 3x3 maxpool used for ImageNet\n",
        "  # Stage layers\n",
        "  self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
        "  self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "  self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "  self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "  self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "  self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "  # Weight initialization\n",
        "  for m in self.modules():\n",
        "   if isinstance(m, nn.Conv2d):\n",
        "    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "   elif isinstance(m, nn.BatchNorm2d):\n",
        "    nn.init.constant_(m.weight, 1)\n",
        "    nn.init.constant_(m.bias, 0)\n",
        "\n",
        " def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "  downsample = None\n",
        "  if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "   downsample = nn.Sequential(\n",
        "    nn.Conv2d(\n",
        "     self.in_channels,\n",
        "     out_channels * block.expansion,\n",
        "     kernel_size=1,\n",
        "     stride=stride,\n",
        "     bias=False,\n",
        "    ),\n",
        "    nn.BatchNorm2d(out_channels * block.expansion),\n",
        "   )\n",
        "\n",
        "  layers = []\n",
        "  layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "  self.in_channels = out_channels * block.expansion\n",
        "  for _ in range(1, blocks):\n",
        "   layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        " def forward(self, x):\n",
        "  x = self.conv1(x)\n",
        "  x = self.bn1(x)\n",
        "  x = self.relu(x)\n",
        "  # no maxpool\n",
        "\n",
        "  x = self.layer1(x)\n",
        "  x = self.layer2(x)\n",
        "  x = self.layer3(x)\n",
        "  x = self.layer4(x)\n",
        "\n",
        "  x = self.avgpool(x)\n",
        "  x = torch.flatten(x, 1)\n",
        "  x = self.fc(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "def resnet50_cifar(num_classes=100):\n",
        " return ResNetCIFAR(Bottleneck, [3, 4, 6, 3], num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe9JSzWI8B_v",
        "outputId": "9f8a3c39-df6b-4e26-d9c5-d5d589ad255f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]           4,096\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "            Conv2d-7           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
            "              ReLU-9           [-1, 64, 32, 32]               0\n",
            "           Conv2d-10          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-11          [-1, 256, 32, 32]             512\n",
            "           Conv2d-12          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-13          [-1, 256, 32, 32]             512\n",
            "             ReLU-14          [-1, 256, 32, 32]               0\n",
            "       Bottleneck-15          [-1, 256, 32, 32]               0\n",
            "           Conv2d-16           [-1, 64, 32, 32]          16,384\n",
            "      BatchNorm2d-17           [-1, 64, 32, 32]             128\n",
            "             ReLU-18           [-1, 64, 32, 32]               0\n",
            "           Conv2d-19           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
            "             ReLU-21           [-1, 64, 32, 32]               0\n",
            "           Conv2d-22          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-23          [-1, 256, 32, 32]             512\n",
            "             ReLU-24          [-1, 256, 32, 32]               0\n",
            "       Bottleneck-25          [-1, 256, 32, 32]               0\n",
            "           Conv2d-26           [-1, 64, 32, 32]          16,384\n",
            "      BatchNorm2d-27           [-1, 64, 32, 32]             128\n",
            "             ReLU-28           [-1, 64, 32, 32]               0\n",
            "           Conv2d-29           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-30           [-1, 64, 32, 32]             128\n",
            "             ReLU-31           [-1, 64, 32, 32]               0\n",
            "           Conv2d-32          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-33          [-1, 256, 32, 32]             512\n",
            "             ReLU-34          [-1, 256, 32, 32]               0\n",
            "       Bottleneck-35          [-1, 256, 32, 32]               0\n",
            "           Conv2d-36          [-1, 128, 32, 32]          32,768\n",
            "      BatchNorm2d-37          [-1, 128, 32, 32]             256\n",
            "             ReLU-38          [-1, 128, 32, 32]               0\n",
            "           Conv2d-39          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-40          [-1, 128, 16, 16]             256\n",
            "             ReLU-41          [-1, 128, 16, 16]               0\n",
            "           Conv2d-42          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-43          [-1, 512, 16, 16]           1,024\n",
            "           Conv2d-44          [-1, 512, 16, 16]         131,072\n",
            "      BatchNorm2d-45          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-46          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-47          [-1, 512, 16, 16]               0\n",
            "           Conv2d-48          [-1, 128, 16, 16]          65,536\n",
            "      BatchNorm2d-49          [-1, 128, 16, 16]             256\n",
            "             ReLU-50          [-1, 128, 16, 16]               0\n",
            "           Conv2d-51          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-52          [-1, 128, 16, 16]             256\n",
            "             ReLU-53          [-1, 128, 16, 16]               0\n",
            "           Conv2d-54          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-55          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-56          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-57          [-1, 512, 16, 16]               0\n",
            "           Conv2d-58          [-1, 128, 16, 16]          65,536\n",
            "      BatchNorm2d-59          [-1, 128, 16, 16]             256\n",
            "             ReLU-60          [-1, 128, 16, 16]               0\n",
            "           Conv2d-61          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-62          [-1, 128, 16, 16]             256\n",
            "             ReLU-63          [-1, 128, 16, 16]               0\n",
            "           Conv2d-64          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-65          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-66          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-67          [-1, 512, 16, 16]               0\n",
            "           Conv2d-68          [-1, 128, 16, 16]          65,536\n",
            "      BatchNorm2d-69          [-1, 128, 16, 16]             256\n",
            "             ReLU-70          [-1, 128, 16, 16]               0\n",
            "           Conv2d-71          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-72          [-1, 128, 16, 16]             256\n",
            "             ReLU-73          [-1, 128, 16, 16]               0\n",
            "           Conv2d-74          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-75          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-76          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-77          [-1, 512, 16, 16]               0\n",
            "           Conv2d-78          [-1, 256, 16, 16]         131,072\n",
            "      BatchNorm2d-79          [-1, 256, 16, 16]             512\n",
            "             ReLU-80          [-1, 256, 16, 16]               0\n",
            "           Conv2d-81            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-82            [-1, 256, 8, 8]             512\n",
            "             ReLU-83            [-1, 256, 8, 8]               0\n",
            "           Conv2d-84           [-1, 1024, 8, 8]         262,144\n",
            "      BatchNorm2d-85           [-1, 1024, 8, 8]           2,048\n",
            "           Conv2d-86           [-1, 1024, 8, 8]         524,288\n",
            "      BatchNorm2d-87           [-1, 1024, 8, 8]           2,048\n",
            "             ReLU-88           [-1, 1024, 8, 8]               0\n",
            "       Bottleneck-89           [-1, 1024, 8, 8]               0\n",
            "           Conv2d-90            [-1, 256, 8, 8]         262,144\n",
            "      BatchNorm2d-91            [-1, 256, 8, 8]             512\n",
            "             ReLU-92            [-1, 256, 8, 8]               0\n",
            "           Conv2d-93            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-94            [-1, 256, 8, 8]             512\n",
            "             ReLU-95            [-1, 256, 8, 8]               0\n",
            "           Conv2d-96           [-1, 1024, 8, 8]         262,144\n",
            "      BatchNorm2d-97           [-1, 1024, 8, 8]           2,048\n",
            "             ReLU-98           [-1, 1024, 8, 8]               0\n",
            "       Bottleneck-99           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-100            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-101            [-1, 256, 8, 8]             512\n",
            "            ReLU-102            [-1, 256, 8, 8]               0\n",
            "          Conv2d-103            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-104            [-1, 256, 8, 8]             512\n",
            "            ReLU-105            [-1, 256, 8, 8]               0\n",
            "          Conv2d-106           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-107           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-108           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-109           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-110            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-111            [-1, 256, 8, 8]             512\n",
            "            ReLU-112            [-1, 256, 8, 8]               0\n",
            "          Conv2d-113            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-114            [-1, 256, 8, 8]             512\n",
            "            ReLU-115            [-1, 256, 8, 8]               0\n",
            "          Conv2d-116           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-117           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-118           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-119           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-120            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-121            [-1, 256, 8, 8]             512\n",
            "            ReLU-122            [-1, 256, 8, 8]               0\n",
            "          Conv2d-123            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-124            [-1, 256, 8, 8]             512\n",
            "            ReLU-125            [-1, 256, 8, 8]               0\n",
            "          Conv2d-126           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-127           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-128           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-129           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-130            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-131            [-1, 256, 8, 8]             512\n",
            "            ReLU-132            [-1, 256, 8, 8]               0\n",
            "          Conv2d-133            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-134            [-1, 256, 8, 8]             512\n",
            "            ReLU-135            [-1, 256, 8, 8]               0\n",
            "          Conv2d-136           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-137           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-138           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-139           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-140            [-1, 512, 8, 8]         524,288\n",
            "     BatchNorm2d-141            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-142            [-1, 512, 8, 8]               0\n",
            "          Conv2d-143            [-1, 512, 4, 4]       2,359,296\n",
            "     BatchNorm2d-144            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-145            [-1, 512, 4, 4]               0\n",
            "          Conv2d-146           [-1, 2048, 4, 4]       1,048,576\n",
            "     BatchNorm2d-147           [-1, 2048, 4, 4]           4,096\n",
            "          Conv2d-148           [-1, 2048, 4, 4]       2,097,152\n",
            "     BatchNorm2d-149           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-150           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-151           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-152            [-1, 512, 4, 4]       1,048,576\n",
            "     BatchNorm2d-153            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-154            [-1, 512, 4, 4]               0\n",
            "          Conv2d-155            [-1, 512, 4, 4]       2,359,296\n",
            "     BatchNorm2d-156            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-157            [-1, 512, 4, 4]               0\n",
            "          Conv2d-158           [-1, 2048, 4, 4]       1,048,576\n",
            "     BatchNorm2d-159           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-160           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-161           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-162            [-1, 512, 4, 4]       1,048,576\n",
            "     BatchNorm2d-163            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-164            [-1, 512, 4, 4]               0\n",
            "          Conv2d-165            [-1, 512, 4, 4]       2,359,296\n",
            "     BatchNorm2d-166            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-167            [-1, 512, 4, 4]               0\n",
            "          Conv2d-168           [-1, 2048, 4, 4]       1,048,576\n",
            "     BatchNorm2d-169           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-170           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-171           [-1, 2048, 4, 4]               0\n",
            "AdaptiveAvgPool2d-172           [-1, 2048, 1, 1]               0\n",
            "          Linear-173                  [-1, 100]         204,900\n",
            "================================================================\n",
            "Total params: 23,705,252\n",
            "Trainable params: 23,705,252\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 88.58\n",
            "Params size (MB): 90.43\n",
            "Estimated Total Size (MB): 179.02\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = resnet50_cifar().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def topk_accuracy(output, target, k=5):\n",
        "    \"\"\"\n",
        "    Calculates the top-k accuracy for a given output and target.\n",
        "\n",
        "    Args:\n",
        "        output (torch.Tensor): The model's raw output logits, typically from the last layer.\n",
        "        target (torch.Tensor): The ground-truth labels.\n",
        "        k (int): The number of top predictions to consider.\n",
        "\n",
        "    Returns:\n",
        "        float: The top-k accuracy.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        # Get the top k predictions\n",
        "        _, topk_preds = output.topk(k, dim=1, largest=True, sorted=True)\n",
        "\n",
        "        # Reshape the target tensor for comparison\n",
        "        target_reshaped = target.view(1, -1).expand_as(topk_preds)\n",
        "\n",
        "        # Check if any of the top k predictions match the true label\n",
        "        correct = (topk_preds == target_reshaped)\n",
        "\n",
        "        # Calculate the number of correct predictions\n",
        "        correct_count = correct.any(dim=0).sum().item()\n",
        "\n",
        "        # Return the accuracy as a percentage\n",
        "        return (correct_count / target.size(0))\n"
      ],
      "metadata": {
        "id": "Om5ZmGWrph3g"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "imHnmYf6RccL"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = resnet50_cifar().to(device)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1) ## Learning: adjust LR to a smaller value after every 5 epochs for fine tuning\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "x-ia4Qeg8rOD"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "test_top5_acc = [] # New list to store top-5 accuracy\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(data)\n",
        "        loss = F.cross_entropy(y_pred, target)\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = y_pred.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        processed += len(data)\n",
        "\n",
        "        pbar.set_description(desc=f'Loss={loss.item():.4f} Batch_id={batch_idx} Accuracy={100*correct/processed:.2f}%')\n",
        "        train_acc.append(100*correct/processed)\n",
        "\n",
        "    # Note: The learning rate scheduler should be called at the end of the epoch,\n",
        "    # as is standard practice.\n",
        "    # scheduler.step()\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    correct_top1 = 0\n",
        "    correct_top5 = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "\n",
        "            # Top-1 accuracy calculation\n",
        "            pred_top1 = output.argmax(dim=1, keepdim=True)\n",
        "            correct_top1 += pred_top1.eq(target.view_as(pred_top1)).sum().item()\n",
        "\n",
        "            # Top-5 accuracy calculation\n",
        "            # correct_top5 += topk_accuracy(output, target, k=5)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    top1_acc = 100. * correct_top1 / len(test_loader.dataset)\n",
        "    # top5_acc = 100. * correct_top5 / len(test_loader.dataset)\n",
        "\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f} ,Top-1 Accuracy: {correct_top1}/{len(test_loader.dataset)} ({top1_acc:.2f}%)%\\n')\n",
        "\n",
        "    test_acc.append(top1_acc)\n",
        "    # test_top5_acc.append(top5_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "KP6zxmOEaOvv"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data import DataLoader\n",
        "# import torchvision\n",
        "# import torchvision.transforms as transforms\n",
        "# from torchvision.datasets import CIFAR100\n",
        "# from tqdm import tqdm\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # --- (Your model classes: Bottleneck, ResNetCIFAR, resnet50_cifar) ---\n",
        "# # Paste your model code here or ensure it's in the same scope.\n",
        "\n",
        "# def lr_finder(model, device, train_loader, optimizer, criterion, start_lr, end_lr, num_iter):\n",
        "#     # Save the initial state of the model and optimizer\n",
        "#     initial_model_state = model.state_dict()\n",
        "#     initial_optimizer_state = optimizer.state_dict()\n",
        "\n",
        "#     # Create a temporary scheduler\n",
        "#     lr_lambda = lambda iteration: (end_lr / start_lr)**(iteration / num_iter)\n",
        "#     scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "#     # Move model to device and set to training mode\n",
        "#     model.to(device)\n",
        "#     model.train()\n",
        "\n",
        "#     lrs = []\n",
        "#     losses = []\n",
        "\n",
        "#     # Start with a very low learning rate\n",
        "#     for param_group in optimizer.param_groups:\n",
        "#         param_group['lr'] = start_lr\n",
        "\n",
        "#     # Begin the LR search\n",
        "#     pbar = tqdm(enumerate(train_loader), total=num_iter)\n",
        "#     for batch_idx, (data, target) in pbar:\n",
        "#         if batch_idx >= num_iter:\n",
        "#             break\n",
        "\n",
        "#         # Get samples and move to device\n",
        "#         data, target = data.to(device), target.to(device)\n",
        "\n",
        "#         # Zero gradients\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # Predict and calculate loss\n",
        "#         y_pred = model(data)\n",
        "#         loss = criterion(y_pred, target)\n",
        "\n",
        "#         # Backpropagation\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # --- FIX: Access the learning rate correctly ---\n",
        "#         # The optimizer.param_groups is a list, so indexing with an integer is necessary.\n",
        "#         lrs.append(optimizer.param_groups[0]['lr'])\n",
        "#         losses.append(loss.item())\n",
        "\n",
        "#         # Step the scheduler to increase LR\n",
        "#         scheduler.step()\n",
        "\n",
        "#         # Update progress bar\n",
        "#         pbar.set_description(desc=f'LR: {lrs[-1]:.6f}, Loss: {losses[-1]:.4f}')\n",
        "\n",
        "#     # Reset model and optimizer to their initial states\n",
        "#     model.load_state_dict(initial_model_state)\n",
        "#     optimizer.load_state_dict(initial_optimizer_state)\n",
        "\n",
        "#     return lrs, losses\n",
        "\n",
        "# def plot_lr_finder(lrs, losses, skip_start=10, skip_end=5):\n",
        "#     # Smooth the loss curve\n",
        "#     smoothed_losses = []\n",
        "#     for i in range(len(losses)):\n",
        "#         smoothed_losses.append(np.mean(losses[max(0, i - 10):i + 1]))\n",
        "\n",
        "#     # Plot the results\n",
        "#     plt.figure(figsize=(10, 6))\n",
        "#     plt.plot(lrs[skip_start:-skip_end], smoothed_losses[skip_start:-skip_end])\n",
        "#     plt.xscale('log')\n",
        "#     plt.xlabel('Learning Rate (log scale)')\n",
        "#     plt.ylabel('Loss')\n",
        "#     plt.title('Learning Rate Finder')\n",
        "#     plt.grid(True)\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     # 1. Device configuration\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#     # 3. Model, Loss, and Adam Optimizer\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
        "\n",
        "#     # 4. Run the LR Finder test\n",
        "#     start_lr = 1e-7\n",
        "#     end_lr = 1e-1\n",
        "#     num_iter = 300\n",
        "\n",
        "#     print(\"Starting LR Finder...\")\n",
        "#     lrs, losses = lr_finder(model, device, train_loader, optimizer, criterion, start_lr, end_lr, num_iter)\n",
        "#     print(\"LR Finder finished.\")\n",
        "\n",
        "#     # 5. Plot and suggest LR\n",
        "#     plot_lr_finder(lrs, losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5vSFWk6-8vk2",
        "outputId": "4a9767d2-2715-4d7e-c3f2-d6926222f952"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=3.9321 Batch_id=390 Accuracy=6.70%: 100%|██████████| 391/391 [02:38<00:00,  2.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 23.9258 ,Top-1 Accuracy: 936/10000 (9.36%)%\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=3.1624 Batch_id=390 Accuracy=14.76%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 3.4850 ,Top-1 Accuracy: 1810/10000 (18.10%)%\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=2.7384 Batch_id=390 Accuracy=21.92%: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 2.9600 ,Top-1 Accuracy: 2743/10000 (27.43%)%\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=2.4910 Batch_id=390 Accuracy=28.83%: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 2.5775 ,Top-1 Accuracy: 3406/10000 (34.06%)%\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=2.4860 Batch_id=390 Accuracy=34.39%: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 2.3791 ,Top-1 Accuracy: 3867/10000 (38.67%)%\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=2.7651 Batch_id=390 Accuracy=38.55%: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 2.1087 ,Top-1 Accuracy: 4292/10000 (42.92%)%\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=1.9039 Batch_id=390 Accuracy=42.83%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 2.1089 ,Top-1 Accuracy: 4527/10000 (45.27%)%\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=1.7541 Batch_id=390 Accuracy=46.06%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.8808 ,Top-1 Accuracy: 4882/10000 (48.82%)%\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=1.6534 Batch_id=390 Accuracy=48.70%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.7559 ,Top-1 Accuracy: 5154/10000 (51.54%)%\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=1.7156 Batch_id=390 Accuracy=51.57%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.7418 ,Top-1 Accuracy: 5420/10000 (54.20%)%\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.3732 Batch_id=390 Accuracy=53.27%: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.4508 ,Top-1 Accuracy: 5533/10000 (55.33%)%\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.4093 Batch_id=390 Accuracy=55.86%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.2151 ,Top-1 Accuracy: 5742/10000 (57.42%)%\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.4854 Batch_id=390 Accuracy=57.96%: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4861 ,Top-1 Accuracy: 5950/10000 (59.50%)%\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.2455 Batch_id=390 Accuracy=59.80%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.5134 ,Top-1 Accuracy: 5969/10000 (59.69%)%\n",
            "\n",
            "EPOCH: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.3357 Batch_id=390 Accuracy=61.18%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3929 ,Top-1 Accuracy: 6139/10000 (61.39%)%\n",
            "\n",
            "EPOCH: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.0888 Batch_id=390 Accuracy=62.75%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4104 ,Top-1 Accuracy: 6164/10000 (61.64%)%\n",
            "\n",
            "EPOCH: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.2390 Batch_id=390 Accuracy=63.55%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4149 ,Top-1 Accuracy: 6174/10000 (61.74%)%\n",
            "\n",
            "EPOCH: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.0990 Batch_id=390 Accuracy=65.28%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3800 ,Top-1 Accuracy: 6327/10000 (63.27%)%\n",
            "\n",
            "EPOCH: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.1826 Batch_id=390 Accuracy=66.75%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3102 ,Top-1 Accuracy: 6452/10000 (64.52%)%\n",
            "\n",
            "EPOCH: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9868 Batch_id=390 Accuracy=68.02%: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3159 ,Top-1 Accuracy: 6568/10000 (65.68%)%\n",
            "\n",
            "EPOCH: 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.3704 Batch_id=390 Accuracy=69.29%: 100%|██████████| 391/391 [02:37<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3313 ,Top-1 Accuracy: 6492/10000 (64.92%)%\n",
            "\n",
            "EPOCH: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7927 Batch_id=390 Accuracy=70.63%: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.2949 ,Top-1 Accuracy: 6601/10000 (66.01%)%\n",
            "\n",
            "EPOCH: 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9818 Batch_id=390 Accuracy=71.96%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3043 ,Top-1 Accuracy: 6713/10000 (67.13%)%\n",
            "\n",
            "EPOCH: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.0825 Batch_id=390 Accuracy=72.47%: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3650 ,Top-1 Accuracy: 6649/10000 (66.49%)%\n",
            "\n",
            "EPOCH: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8392 Batch_id=390 Accuracy=73.34%: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3111 ,Top-1 Accuracy: 6727/10000 (67.27%)%\n",
            "\n",
            "EPOCH: 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8983 Batch_id=390 Accuracy=74.58%: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3114 ,Top-1 Accuracy: 6721/10000 (67.21%)%\n",
            "\n",
            "EPOCH: 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.0721 Batch_id=390 Accuracy=75.63%: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3233 ,Top-1 Accuracy: 6789/10000 (67.89%)%\n",
            "\n",
            "EPOCH: 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9872 Batch_id=128 Accuracy=77.07%:  33%|███▎      | 129/391 [00:53<01:47,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1730606257.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCH:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2829834487.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch+1)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5MFqE1yaSjn"
      },
      "outputs": [],
      "source": [
        "t = [t_items.item() for t_items in train_losses]\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
        "axs[0, 0].plot(t)\n",
        "axs[0, 0].set_title(\"Training Loss\")\n",
        "axs[1, 0].plot(train_acc[4000:])\n",
        "axs[1, 0].set_title(\"Training Accuracy\")\n",
        "axs[0, 1].plot(test_losses)\n",
        "axs[0, 1].set_title(\"Test Loss\")\n",
        "axs[1, 1].plot(test_acc)\n",
        "axs[1, 1].set_title(\"Test Accuracy\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPVcOP4oky8P5wMG13BLdD0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}